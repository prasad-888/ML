{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCAPWR2s3nzA"
   },
   "source": [
    "\n",
    "In this question you will write Python code for processing, analyzing and understanding the social network **Reddit** (www.reddit.com). Reddit is a platform that allows users to upload posts and comment on them, and is divided in _subreddits_, often covering specific themes or areas of interest (for example, [world news](https://www.reddit.com/r/worldnews/), [ukpolitics](https://www.reddit.com/r/ukpolitics/) or [nintendo](https://www.reddit.com/r/nintendo)). You are provided with a subset of Reddit with posts from Covid-related subreddits (e.g., _CoronavirusUK_ or _NoNewNormal_), as well as randomly selected subreddits (e.g., _donaldtrump_ or _razer_).\n",
    "\n",
    "The `csv` dataset you are provided contains one row per post, and has information about three entities: **posts**, **users** and **subreddits**. The column names are self-explanatory: columns starting with the prefix `user_` describe users, those starting with the prefix `subr_` describe subreddits, the `subreddit` column is the subreddit name, and the rest of the columns are post attributes (`author`, `posted_at`, `title` and post text - the `selftext` column-, number of comments - `num_comments`, `score`, etc.).\n",
    "\n",
    "In this exercise, you are asked to perform a number of operations to gain insights from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Pm74v1u4d6G",
    "outputId": "9928445a-04d5-4b3d-a662-44c47335fea0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# suggested imports\n",
    "import pandas as pd\n",
    "from nltk.tag import pos_tag\n",
    "import re\n",
    "from collections import defaultdict,Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "tqdm.pandas()\n",
    "from ast import literal_eval\n",
    "# nltk imports, note that these outputs may be different if you are using colab or local jupyter notebooks\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfNsDQ253nzJ",
    "outputId": "2fdcb74b-775a-4163-9677-41b3fe48e61e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://media.githubusercontent.com/media/Ai-Adventures/Test_Datasets/main/ML_Test_1.csv\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "import pandas as pd\n",
    "module_url = f\"https://media.githubusercontent.com/media/Ai-Adventures/Test_Datasets/main/ML_Test_1.csv\"\n",
    "module_name = 'ML_Test_1.csv'\n",
    "print(f'Fetching {module_url}')\n",
    "#with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
    "with request.urlopen(module_url) as f, open(module_name,'w') as outf:\n",
    "  a = f.read()\n",
    "  outf.write(a.decode('utf-8'))\n",
    "\n",
    "\n",
    "df = pd.read_csv('ML_Test_1.csv')\n",
    "# this fills empty cells with empty strings\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "CNfbxg2X3nzK",
    "outputId": "f5bd1cc6-2b54-4abf-c2e7-3ae36d637815"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f2c74582-0264-4374-9c94-cd600d3576f5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>posted_at</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subr_created_at</th>\n",
       "      <th>subr_description</th>\n",
       "      <th>subr_faved_by</th>\n",
       "      <th>subr_numb_members</th>\n",
       "      <th>subr_numb_posts</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>user_num_posts</th>\n",
       "      <th>user_registered_at</th>\n",
       "      <th>user_upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Howitzer-</td>\n",
       "      <td>2020-08-17 20:26:04</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>Subreddit about Donald Trump</td>\n",
       "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
       "      <td>30053</td>\n",
       "      <td>796986</td>\n",
       "      <td>donaldtrump</td>\n",
       "      <td>BREAKING: Trump to begin hiding in mailboxes t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4661</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>-0.658599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Howitzer-</td>\n",
       "      <td>2020-07-06 17:01:48</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>Subreddit about Donald Trump</td>\n",
       "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
       "      <td>30053</td>\n",
       "      <td>796986</td>\n",
       "      <td>donaldtrump</td>\n",
       "      <td>Joe Biden's America</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>4661</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>-0.658599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Howitzer-</td>\n",
       "      <td>2020-09-09 02:29:02</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>Subreddit about Donald Trump</td>\n",
       "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
       "      <td>30053</td>\n",
       "      <td>796986</td>\n",
       "      <td>donaldtrump</td>\n",
       "      <td>4 more years and we can erase his legacy for g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4661</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>-0.658599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-Howitzer-</td>\n",
       "      <td>2020-06-23 23:02:39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>Subreddit about Donald Trump</td>\n",
       "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
       "      <td>30053</td>\n",
       "      <td>796986</td>\n",
       "      <td>donaldtrump</td>\n",
       "      <td>Revelation 9:6 [Transhumanism: The New Religio...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4661</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>-0.658599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Howitzer-</td>\n",
       "      <td>2020-08-07 04:13:53</td>\n",
       "      <td>32</td>\n",
       "      <td>622</td>\n",
       "      <td></td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>Subreddit about Donald Trump</td>\n",
       "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
       "      <td>30053</td>\n",
       "      <td>796986</td>\n",
       "      <td>donaldtrump</td>\n",
       "      <td>LOOK HERE, FAT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4661</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>-0.658599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2c74582-0264-4374-9c94-cd600d3576f5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f2c74582-0264-4374-9c94-cd600d3576f5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f2c74582-0264-4374-9c94-cd600d3576f5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       author            posted_at  num_comments  score selftext  \\\n",
       "0  -Howitzer-  2020-08-17 20:26:04            19      1            \n",
       "1  -Howitzer-  2020-07-06 17:01:48             1      3            \n",
       "2  -Howitzer-  2020-09-09 02:29:02             3      1            \n",
       "3  -Howitzer-  2020-06-23 23:02:39             2      1            \n",
       "4  -Howitzer-  2020-08-07 04:13:53            32    622            \n",
       "\n",
       "  subr_created_at              subr_description  \\\n",
       "0      2009-04-29  Subreddit about Donald Trump   \n",
       "1      2009-04-29  Subreddit about Donald Trump   \n",
       "2      2009-04-29  Subreddit about Donald Trump   \n",
       "3      2009-04-29  Subreddit about Donald Trump   \n",
       "4      2009-04-29  Subreddit about Donald Trump   \n",
       "\n",
       "                                       subr_faved_by  subr_numb_members  \\\n",
       "0  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
       "1  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
       "2  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
       "3  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
       "4  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
       "\n",
       "   subr_numb_posts    subreddit  \\\n",
       "0           796986  donaldtrump   \n",
       "1           796986  donaldtrump   \n",
       "2           796986  donaldtrump   \n",
       "3           796986  donaldtrump   \n",
       "4           796986  donaldtrump   \n",
       "\n",
       "                                               title  total_awards_received  \\\n",
       "0  BREAKING: Trump to begin hiding in mailboxes t...                      0   \n",
       "1                                Joe Biden's America                      0   \n",
       "2  4 more years and we can erase his legacy for g...                      0   \n",
       "3  Revelation 9:6 [Transhumanism: The New Religio...                      0   \n",
       "4                                     LOOK HERE, FAT                      0   \n",
       "\n",
       "   upvote_ratio  user_num_posts user_registered_at  user_upvote_ratio  \n",
       "0          1.00            4661         2012-11-09          -0.658599  \n",
       "1          0.67            4661         2012-11-09          -0.658599  \n",
       "2          1.00            4661         2012-11-09          -0.658599  \n",
       "3          1.00            4661         2012-11-09          -0.658599  \n",
       "4          0.88            4661         2012-11-09          -0.658599  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyQyR27z48nr"
   },
   "source": [
    "## P1.1 - Text data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLUtCUL853Ln"
   },
   "source": [
    "### P1.1.1 - Faved by as lists\n",
    "\n",
    "The column `subr_faved_by` contains an array of values (names of redditors who added the subreddit to which the current post was submitted), but unfortunately they are in text format, and you would not be able to process them properly without converting them to a suitable python type. You must convert these string values to Python lists, going from\n",
    "\n",
    "```python\n",
    "'[\"user1\", \"user2\" ... ]'\n",
    "```\n",
    "\n",
    "to\n",
    "\n",
    "```python\n",
    "[\"user1\", \"user2\" ... ]\n",
    "```\n",
    "\n",
    "**What to implement:** Implement a function `transform_faves(df)` which takes as input the original dataframe and returns the same dataframe, but with one additional column called `subr_faved_by_as_list`, where you have the same information as in `subr_faved_by`, but as a python list instead of a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWZf7Xnrai1-"
   },
   "outputs": [],
   "source": [
    "def transform_faves(df):\n",
    "    df['subr_faved_by_as_list'] = df['subr_faved_by'].str.split(' ', n = 1, expand = True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = transform_faves(df)\n",
    "#print(df['subr_faved_by_as_list'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhZ3u5aS3rrm"
   },
   "source": [
    "### P1.1.2 - Merge titles and text bodies\n",
    "\n",
    "All Reddit posts need to have a title, but a text body is optional. However, we want to be able to access all free text information for each post without having to look at two columns every time.\n",
    "\n",
    "**What to implement**: A function `concat(df)` that will take as input the original dataframe and will return it with an additional column called `full_text`, which will concatenate `title` and `selftext` columns, but with the following restrictions:\n",
    "\n",
    "- 1) Wrap the title between `<title>` and `</title>` tags.\n",
    "- 2) Add a new line (`\\n`) between title and selftext, but only in cases where you have both values (see instruction 4).\n",
    "- 3) Wrap the selftext between `<selftext>` and `</selftext>`.\n",
    "- 4) You **must not** include the tags in points (1) or (3) if the values for these columns is missing. We will consider a missing value either an empty value (empty string) or a string of only one character (e.g., an emoji). Also, the value of a `full_text` column must not end in the new line character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsmY-JB39N2m",
    "outputId": "b436638c-bdf4-4621-d0fb-27b04c1ac339"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 2, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'full_text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   4242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4243\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4244\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'full_text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-401f5d3226ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-401f5d3226ed>\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selftext'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3195\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3197\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2600\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2601\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   4244\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4245\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4246\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4247\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   4345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4346\u001b[0m         block = make_block(values=value, ndim=self.ndim,\n\u001b[0;32m-> 4347\u001b[0;31m                            placement=slice(loc, loc + 1))\n\u001b[0m\u001b[1;32m   4348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4349\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   3203\u001b[0m                      placement=placement, dtype=dtype)\n\u001b[1;32m   3204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3205\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3207\u001b[0m \u001b[0;31m# TODO: flexible with index=None and/or items=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m   2301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2302\u001b[0m         super(ObjectBlock, self).__init__(values, ndim=ndim,\n\u001b[0;32m-> 2303\u001b[0;31m                                           placement=placement)\n\u001b[0m\u001b[1;32m   2304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2305\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    123\u001b[0m             raise ValueError(\n\u001b[1;32m    124\u001b[0m                 \u001b[0;34m'Wrong number of items passed {val}, placement implies '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 '{mgr}'.format(val=len(self.values), mgr=len(self.mgr_locs)))\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 2, placement implies 1"
     ]
    }
   ],
   "source": [
    "def concat(df):\n",
    "    # your code here\n",
    "    df.fillna(np.nan,inplace=True) # filling up missing values with nan \n",
    "    title=df['title'].values.ravel() # creating a 1D a... \n",
    "    \n",
    "    df['full_text'] = pd.concat([df['title'],df['selftext']],axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = concat(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADWvbAIe4TVd"
   },
   "source": [
    "### P1.1.3 - Enrich posts\n",
    "\n",
    "We would like to augment our text data with linguistic information. To this end, we will _tokenize_, apply _part-of-speech tagging_, and then we will _lower case_ all the posts.\n",
    "\n",
    "**What to implement**: A function `enrich_posts(df)` that will take as input the original dataframe and will return it with **two** additional columns: `enriched_title` and `enriched_selftext`. These columns will contain tokenized, pos-tagged and lower cased versions of the original text. **You must implement them in this order**, because the pos tagger uses casing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nDnaSwI46T_"
   },
   "outputs": [],
   "source": [
    "def enrich_posts(df):\n",
    "    # your code here\n",
    "    return df\n",
    "\n",
    "df = enrich_posts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8E010UbQyML"
   },
   "source": [
    "## P1.2 - Answering questions with pandas\n",
    "\n",
    "In this question, your task is to use pandas to answer questions about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZmG2VIYQ93I"
   },
   "source": [
    "### P1.2.1 - Users with best scores\n",
    "\n",
    "- Find the users with the highest aggregate scores (over all their posts) for the whole dataset. You should restrict your results to only those whose aggregated score is above 10,000 points, in descending order. Your code should generate a dictionary of the form `{author:aggregated_scores ... }`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhW8Rr6QSXDj"
   },
   "outputs": [],
   "source": [
    "def user_best_score(df):\n",
    "    # your code here\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = user_best_score(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woOFrPFQT5cZ"
   },
   "source": [
    "### P1.2.2 - Awarded posts\n",
    "\n",
    "Find the number of posts that have received at least one award. Your query should return only one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdHNA5zgai2a",
    "outputId": "78718056-51a1-495d-c5d0-b54d0c692a4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9977"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['total_awards_received'] >= 1].max()['user_num_posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fpm4EGiKai2b",
    "outputId": "8d3df10c-617d-4841-b629-2bb468762beb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67       1105\n",
       "69       1105\n",
       "818      8292\n",
       "866      6102\n",
       "911      6900\n",
       "1024     6586\n",
       "1076     9286\n",
       "1077     9286\n",
       "1079     9286\n",
       "1086     2248\n",
       "1237     9210\n",
       "1290     4596\n",
       "1322     6219\n",
       "1950     9005\n",
       "1956     9005\n",
       "1957     9005\n",
       "1960     3773\n",
       "2072     8984\n",
       "2127     2923\n",
       "2319     8543\n",
       "2367     5092\n",
       "2461     4063\n",
       "2741     6962\n",
       "2812     4260\n",
       "2817     4260\n",
       "3173     7801\n",
       "3175     7801\n",
       "3318     9602\n",
       "3701     8161\n",
       "3935      726\n",
       "         ... \n",
       "9471     8603\n",
       "9473     8603\n",
       "9687     9829\n",
       "9741     7733\n",
       "9935     6819\n",
       "10063    1083\n",
       "10981    9403\n",
       "12119    1375\n",
       "12349    1066\n",
       "12699    9343\n",
       "12844    4245\n",
       "13163    7238\n",
       "13211    5325\n",
       "13267     510\n",
       "13309     677\n",
       "13426    5886\n",
       "14248    2594\n",
       "14420    1772\n",
       "14738      64\n",
       "15371    6369\n",
       "16080    4542\n",
       "16110    5298\n",
       "16112    5298\n",
       "16456    5861\n",
       "16664    9534\n",
       "17041    2476\n",
       "17361    4838\n",
       "18599    3862\n",
       "18823    4604\n",
       "19639     355\n",
       "Name: user_num_posts, Length: 119, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['total_awards_received'] >= 1]['user_num_posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fVuaWmmUGVW",
    "outputId": "1e6334a9-ca6c-420c-9156-3614cd0f55f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>posted_at</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subr_created_at</th>\n",
       "      <th>subr_description</th>\n",
       "      <th>subr_faved_by</th>\n",
       "      <th>subr_numb_members</th>\n",
       "      <th>subr_numb_posts</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>user_num_posts</th>\n",
       "      <th>user_registered_at</th>\n",
       "      <th>user_upvote_ratio</th>\n",
       "      <th>subr_faved_by_as_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Howitzer-</td>\n",
       "      <td>2020-08-17 20:26:04</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>Subreddit about Donald Trump</td>\n",
       "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
       "      <td>30053</td>\n",
       "      <td>796986</td>\n",
       "      <td>donaldtrump</td>\n",
       "      <td>BREAKING: Trump to begin hiding in mailboxes t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4661</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>-0.658599</td>\n",
       "      <td>['vergil_never_cry',</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Howitzer-</td>\n",
       "      <td>2020-07-06 17:01:48</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>Subreddit about Donald Trump</td>\n",
       "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
       "      <td>30053</td>\n",
       "      <td>796986</td>\n",
       "      <td>donaldtrump</td>\n",
       "      <td>Joe Biden's America</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>4661</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>-0.658599</td>\n",
       "      <td>['vergil_never_cry',</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Howitzer-</td>\n",
       "      <td>2020-09-09 02:29:02</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>Subreddit about Donald Trump</td>\n",
       "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
       "      <td>30053</td>\n",
       "      <td>796986</td>\n",
       "      <td>donaldtrump</td>\n",
       "      <td>4 more years and we can erase his legacy for g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4661</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>-0.658599</td>\n",
       "      <td>['vergil_never_cry',</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-Howitzer-</td>\n",
       "      <td>2020-06-23 23:02:39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>Subreddit about Donald Trump</td>\n",
       "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
       "      <td>30053</td>\n",
       "      <td>796986</td>\n",
       "      <td>donaldtrump</td>\n",
       "      <td>Revelation 9:6 [Transhumanism: The New Religio...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4661</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>-0.658599</td>\n",
       "      <td>['vergil_never_cry',</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Howitzer-</td>\n",
       "      <td>2020-08-07 04:13:53</td>\n",
       "      <td>32</td>\n",
       "      <td>622</td>\n",
       "      <td></td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>Subreddit about Donald Trump</td>\n",
       "      <td>['vergil_never_cry', 'Jelegend', 'pianoyeah', ...</td>\n",
       "      <td>30053</td>\n",
       "      <td>796986</td>\n",
       "      <td>donaldtrump</td>\n",
       "      <td>LOOK HERE, FAT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4661</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>-0.658599</td>\n",
       "      <td>['vergil_never_cry',</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author            posted_at  num_comments  score selftext  \\\n",
       "0  -Howitzer-  2020-08-17 20:26:04            19      1            \n",
       "1  -Howitzer-  2020-07-06 17:01:48             1      3            \n",
       "2  -Howitzer-  2020-09-09 02:29:02             3      1            \n",
       "3  -Howitzer-  2020-06-23 23:02:39             2      1            \n",
       "4  -Howitzer-  2020-08-07 04:13:53            32    622            \n",
       "\n",
       "  subr_created_at              subr_description  \\\n",
       "0      2009-04-29  Subreddit about Donald Trump   \n",
       "1      2009-04-29  Subreddit about Donald Trump   \n",
       "2      2009-04-29  Subreddit about Donald Trump   \n",
       "3      2009-04-29  Subreddit about Donald Trump   \n",
       "4      2009-04-29  Subreddit about Donald Trump   \n",
       "\n",
       "                                       subr_faved_by  subr_numb_members  \\\n",
       "0  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
       "1  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
       "2  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
       "3  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
       "4  ['vergil_never_cry', 'Jelegend', 'pianoyeah', ...              30053   \n",
       "\n",
       "   subr_numb_posts    subreddit  \\\n",
       "0           796986  donaldtrump   \n",
       "1           796986  donaldtrump   \n",
       "2           796986  donaldtrump   \n",
       "3           796986  donaldtrump   \n",
       "4           796986  donaldtrump   \n",
       "\n",
       "                                               title  total_awards_received  \\\n",
       "0  BREAKING: Trump to begin hiding in mailboxes t...                      0   \n",
       "1                                Joe Biden's America                      0   \n",
       "2  4 more years and we can erase his legacy for g...                      0   \n",
       "3  Revelation 9:6 [Transhumanism: The New Religio...                      0   \n",
       "4                                     LOOK HERE, FAT                      0   \n",
       "\n",
       "   upvote_ratio  user_num_posts user_registered_at  user_upvote_ratio  \\\n",
       "0          1.00            4661         2012-11-09          -0.658599   \n",
       "1          0.67            4661         2012-11-09          -0.658599   \n",
       "2          1.00            4661         2012-11-09          -0.658599   \n",
       "3          1.00            4661         2012-11-09          -0.658599   \n",
       "4          0.88            4661         2012-11-09          -0.658599   \n",
       "\n",
       "  subr_faved_by_as_list  \n",
       "0  ['vergil_never_cry',  \n",
       "1  ['vergil_never_cry',  \n",
       "2  ['vergil_never_cry',  \n",
       "3  ['vergil_never_cry',  \n",
       "4  ['vergil_never_cry',  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "def Awarded_posts(df):\n",
    "    # your code here\n",
    "    df.loc[df['total_awards_received'] <= 1]\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "df = Awarded_posts(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVj1WikSUPjO"
   },
   "source": [
    "### P1.2.3 Find Covid\n",
    "\n",
    "Find the name and description of all subreddits where the name starts with `Covid` or `Corona` and the description contains `covid` or `Covid` anywhere. Your code should generate a dictionary of the form#\n",
    "\n",
    "```python\n",
    "  {'Coronavirus':'Place to discuss all things COVID-related',\n",
    "  ...\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6fIWO8BUhu3"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToPttp2-fsXG"
   },
   "source": [
    "### P1.2.4 - Redditors that favorite the most\n",
    "\n",
    "Find the users that have favorited the largest number of subreddits. You must produce a pandas dataframe with **two** columns, with the following format:\n",
    "\n",
    "```python\n",
    "     redditor\t    numb_favs\n",
    "0\tuser1           7\n",
    "1\tuser2           6\n",
    "2\tuser3\t       5\n",
    "3\tuser4           4\n",
    "...\n",
    "```\n",
    "\n",
    "where the first column is a Redditor username and the second column is the number of distinct subreddits he/she has favorited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbFeie3jip44"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsAF9jpblJLp"
   },
   "source": [
    "## P1.3 Ethics\n",
    "\n",
    "Imagine you use the insights gained in this assignment to scan social media for covid-related content, and automatically flag it as `conspiracy` or `not conspiracy` (for example, for hiding potentially harmful tweets or facebook posts). Reflect on the impact of exploiting data science for such an application.\n",
    "\n",
    "\n",
    "Your answer should address the following:\n",
    "- Identify the action that, in your opinion, is the weakest. \n",
    "- Then, justify your choice by critically analyzing the three key principles outlined in the Framework, namely transparency, accountability and fairness. \n",
    "- Finally, you should propose one solution that explicitly addresses one point related to one of these three principles, reflecting on how your solution would improve the data cycle in this particular use case. \n",
    "\n",
    "Your answer should be between 500 and 700 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YJQSO8Amuea"
   },
   "source": [
    "---\n",
    "\n",
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnEwxHMU6Nuc"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
