{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cc7502d-9fe3-4eb0-8d65-967203fbb87c",
   "metadata": {},
   "source": [
    "# Estimators and Transformers\n",
    "Estimators is the name that sklearn people use to refer ML models in sklearn. So, all your ML algorithms like LinearRegressor, GaussianNB, RandomForestClassifier, etc. are estimators.\n",
    "\n",
    "Apart from estimators, sklearn also provides a lot of Tranformers. Transformer are responsible for transforming the input into another form, quite literally. We have already seen a few transformers in the course. Do you remember any of them? LabelEncoder, CountVectorizer, TFidfVectorizer, etc. are all transformers.\n",
    "\n",
    "Both estimators and transformers might look very similar, but they are not.\n",
    "\n",
    "Transformer                                        |                         Estimator\n",
    "\n",
    "Used for data preparation                           |            Used for modeling and making prediction\n",
    "\n",
    "fit()method-findparameters from training data(if needed)|fit()method-findparametersfrom training data\n",
    "\n",
    "transformer() method - apply to training or test data |predict() method - apply to training or test data\n",
    "\n",
    "Eg. LabelEncoder, MinMaxScaler, etc.           |    Eg. LinearRegressor, DecisionTreeClassifier, etc.\n",
    "\n",
    "\n",
    "Now that you know this subtle and important difference between estimators and transformers in sklearn, its becomes very easy to remember the API. It all look very intuitive and obvious.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e004c369-e343-482a-ad37-f4effd4303cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  PolynomialFeatures, PowerTransformer, LabelBinarizer, LabelEncoder, MinMaxScaler,MultiLabelBinarizer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157fa022-a436-4c61-af55-676187a05c54",
   "metadata": {},
   "source": [
    "# Pipelines: The Seamless Workflow\n",
    "Pipelines combine transformers and estimators into a single, streamlined process, ensuring reproducibility and minimizing the risk of data leakage.\n",
    "\n",
    "# Why Use Pipelines?\n",
    "* Simplifies code.\n",
    "* Automates preprocessing and model training.\n",
    "* Ensures consistent transformations during training and testing.\n",
    "\n",
    "\n",
    "__Creating a Pipeline__\n",
    "\n",
    "Hereâ€™s an example pipeline for Random Forest Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69582bf3-6910-4399-a032-5249cd399262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.044]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "X = [[1], [2], [3], [4], [5]]\n",
    "y = [2.1, 2.9, 3.7, 4.5, 5.3]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),                   # Transformer\n",
    "    ('regressor', RandomForestRegressor())            # Estimator\n",
    "])\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "print(pipeline.predict([[2.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b9f6a-334e-462d-a601-2f3e4688ef71",
   "metadata": {},
   "source": [
    "This chapter bridged the gap between classifiers and regressors, showing how versatile algorithms like KNN, SVM, Decision Trees, and Random Forests can adapt to regression tasks. It also introduced the concept of transformers, estimators, and pipelines, demonstrating how these tools simplify and enhance machine-learning workflows. With practical examples and Python code, you're now equipped to tackle real-world regression problems with confidence and creativity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef1894-83ca-4496-80c9-f1ada8ec0f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
